{
  "dataset_reader":{
      "type":"my_copynet_seq2seq",
      "target_namespace": "target_tokens",
      "source_token_indexers": {
        "tokens": {
          "type": "single_id"
        }
      }
  },
  "vocabulary": {
    "min_count": {
      "source_tokens": 5,
      "target_tokens": 5
    }
  },
  "train_data_path": "datasets/json/EN_conll09_trial.json",
  "validation_data_path": "datasets/json/EN_conll09_trial.json",
  "model": {
    "type": "seq2seq_copy_srl",
    "source_embedder":{
	  "tokens": {
          "type": "embedding",
          "embedding_dim": 100,
          "pretrained_file": "https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.100d.txt.gz",
          "trainable": true
      }
    },
    "encoder": {
      "type": "alternating_lstm",
      "input_size": 120, //100 GloVE + 20 PredFlagEmbedding
      "hidden_size": 128,
      "num_layers": 2,
      "recurrent_dropout_probability": 0.1,
      "use_highway": true
    },
    "beam_size": 1,
    "binary_pred_feature_dim": 20,
    "target_embedding_dim": 256,
    "max_decoding_steps": 100,
    "attention": {
      "type": "linear",
      "tensor_1_dim": 256,
      "tensor_2_dim": 256,
      "combination": "x,y",
      "activation": "tanh"
    }
  },
  "iterator": {
    "type": "bucket",
    "sorting_keys": [["source_tokens", "num_tokens"], ["target_tokens", "num_tokens"]],
    "padding_noise": 0.0,
    "batch_size" : 8
  },

  "trainer": {
    "num_epochs": 2,
    "grad_norm": 1.0,
    "patience": 1,
    "optimizer": {
      "type": "adam",
      "lr": 0.0001
    }
  }
}
